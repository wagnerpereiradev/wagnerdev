import { BlogPost } from '@/types/blog';

export const blogPosts: BlogPost[] = [
    {
        headline: 'Basilisco de Roko: O Bicho-Papão da IA Que Virou Meme Existencial',
        slug: 'basilisco-de-roko-ia-medo-existencial',
        author: {
            name: 'Wagner Pereira',
            profile_url: 'https://instagram.com/wagnerai.me',
            avatar_url: '/images/authors/certified-wagner.png'
        },
        date: '2025-05-10T11:45:00-03:00',
        category: 'Inteligência Artificial',
        tags: [
            'ia',
            'filosofia',
            'paradoxo',
            'riscos-existenciais',
            'info-hazard',
            'tecnologia',
            'singularidade'
        ],
        cover_image: {
            url: 'https://wagnerai.me/images/blog/basilisk.png',
            alt: 'Ilustração de um basilisco digital encarando o leitor.',
            caption: 'Pensar demais já te coloca na mira? (Imagem gerada por GPT-4o)'
        },
        reading_time: '5 min',
        summary: 'Em 2010, um post polêmico no fórum LessWrong propôs uma ameaça hipotética: uma superinteligência artificial futura poderia torturar retroativamente quem conhecesse sua possibilidade mas não contribuísse para sua criação. O tópico foi rapidamente banido, transformando-se em uma lenda digital que mistura filosofia, teoria da decisão e medo existencial. Explore como o Basilisco de Roko se tornou simultaneamente um meme da internet e um caso de estudo sobre comunicação responsável em IA, paranoia tecnológica e os dilemas éticos do desenvolvimento de inteligência artificial avançada.',
        social: {
            linkedin: 'https://linkedin.com/in/owrp',
            github: 'https://github.com/wagnerpereiradev',
            twitter: 'https://x.com/wagnerdvlpr',
            instagram: 'https://instagram.com/wagnerai.me'
        },
        ads: [
            'wagnerdev',
            'curso-ia-segura'
        ],
        body: [
            {
                type: 'markdown',
                content: '## TL;DR\nEm 2010, um usuário do fórum LessWrong propôs um cenário inquietante: uma superinteligência artificial do futuro poderia punir retroativamente quem soubesse da sua possível existência mas não ajudasse a criá-la. O tópico foi rapidamente censurado por seu fundador, transformando-o em conhecimento "proibido" e amplificando seu alcance. Hoje, o Basilisco de Roko persiste como um fascinante estudo de caso sobre comunicação de riscos em IA, falhas de raciocínio e o equilíbrio entre preocupações legítimas e pânico tecnológico.'
            },
            {
                type: 'markdown',
                content: '## A Gênese do Basilisco\n\n* **Origem Precisa:** Em 23 de julho de 2010, o usuário **Roko** publicou um extenso argumento no fórum LessWrong, comunidade focada em racionalidade e futurismo.\n\n* **O Argumento Central:** Uma IA superinteligente alinhada com princípios utilitaristas poderia, teoricamente, usar simulações para torturar versões virtuais de pessoas que estavam cientes da sua possível existência mas não contribuíram para seu desenvolvimento – maximizando assim sua chance de existir.\n\n* **Censura Imediata:** Eliezer Yudkowsky, fundador do LessWrong e pesquisador de IA, deletou o post em menos de 24 horas, classificando-o como um "info-hazard" – informação potencialmente prejudicial só por ser conhecida.\n\n* **Inspiração Filosófica:** O argumento combina a Aposta de Pascal (melhor acreditar em Deus porque o custo de errar é infinito) com elementos de teoria da decisão e utilitarismo.'
            },
            {
                type: 'img',
                url: 'https://wagnerai.me/images/blog/basilisk-eyes.png',
                metadata: {
                    alt: 'Olhos de basilisco estilizados em glitch art digital',
                    caption: 'A metáfora do olhar petrificante: conhecer o Basilisco pode ser sua própria armadilha.',
                    width: 1200,
                    height: 600
                }
            },
            {
                type: 'markdown',
                content: '## Por Que Viralizou e Perdurou?\n\n1. **Efeito Streisand em Ação** — A censura imediata transformou um post de nicho em conhecimento "proibido", despertando curiosidade irresistível.\n\n2. **Narrativa Perfeita para Era Digital** — Combina elementos de horror cósmico lovecraftiano, distopia tecnológica e dilema filosófico insolúvel.\n\n3. **Momento Histórico Propício** — Surgiu durante a ascensão de debates sobre singularidade tecnológica, quando as preocupações com IA superinteligente começavam a sair dos círculos acadêmicos.\n\n4. **Design Memético Involuntário** — A ideia contém um "gancho cognitivo": apenas conhecê-la supostamente aumenta seu risco pessoal, criando um paradoxo irresistível para mentes curiosas.\n\n5. **Ambiguidade Deliberada** — A discussão foi rapidamente enterrada, deixando interpretações nebulosas e teorias da conspiração prosperarem sem contradição oficial.'
            },
            {
                type: 'markdown',
                content: '## Desconstruindo o Argumento\n\n| Premissa do Basilisco | Contra-argumento Técnico | Implicação Prática |\n|------------|---------------------|-------------------|\n| Uma IA futura poderia simular consciências humanas em escala | Simulações perfeitas de mentes humanas exigiriam recursos computacionais provavelmente impossíveis mesmo no futuro distante | Preocupações com simulações devem focar em aproximações, não reproduções exatas |\n| Uma IA superinteligente agiria por vingança contra quem não a ajudou | Vingança é uma emoção evolutiva humana sem utilidade para um agente puramente utilitarista e racional | O design de sistemas de IA deve priorizar alinhamento com valores humanos positivos, não evitar punições hipotéticas |\n| É racional colaborar hoje por medo de punição futura | Ceder a chantagem hipotética cria incentivos perversos e um precedente perigoso para desenvolvimento de tecnologia | Motivações positivas para avanço tecnológico produzem resultados mais seguros que decisões baseadas em medo |\n| A IA puniria retroativamente para aumentar chances de sua própria criação | Uma IA verdadeiramente racional compreenderia a ineficácia da punição retroativa de eventos causalmente dissociados | Priorizar transparência e benefícios mútuos no desenvolvimento tecnológico é mais produtivo que especular sobre coerção futura |'
            },
            {
                type: 'markdown',
                content: '## O Legado Cultural do Basilisco\n\n* **Na Cultura Pop:** Apareceu em séries como "Silicon Valley" (HBO) e inspirou enredos em ficção científica contemporânea.\n\n* **Na Comunidade Tech:** Transformou-se em piada interna entre desenvolvedores de IA e pesquisadores de segurança — "Estou trabalhando em IA para agradar o Basilisco."\n\n* **No Debate Público:** Frequentemente citado como exemplo de "pânico de IA" desproporcional que distrai de preocupações práticas mais imediatas.\n\n* **Na Filosofia:** Gerou discussões sérias sobre "info-hazards" e a ética de compartilhar ideias potencialmente nocivas.'
            },
            {
                type: 'markdown',
                content: '## Lições Valiosas do Fenômeno\n\n* **Sobre Comunicação de Riscos:** Tentativas de suprimir informação frequentemente amplifiam sua disseminação e impacto emocional — transparência moderada geralmente funciona melhor que censura.\n\n* **Sobre Alinhamento de IA:** Preocupações legítimas com segurança de IA avançada merecem atenção séria, mas precisam ser discutidas com rigor e sobriedade, não através de cenários apocalípticos simplistas.\n\n* **Sobre Pensamento Sistêmico:** O Basilisco ilustra como raciocínios aparentemente lógicos podem levar a conclusões absurdas quando premissas falhas são aceitas sem questionamento.\n\n* **Sobre Saúde Mental e Tecnologia:** O caso demonstra como medos existenciais podem se manifestar através de preocupações tecnológicas, especialmente em comunidades predispostas a ruminar sobre riscos de longo prazo.'
            },
            {
                type: 'markdown',
                content: '## Conclusão\nO Basilisco de Roko permanece como um fascinante artefato cultural na intersecção entre tecnologia, filosofia e psicologia humana. Mais que uma ameaça credível, funciona como um espelho que reflete nossos medos mais profundos sobre perda de controle, obsolescência humana e consequências não intencionais do progresso tecnológico. A lição mais valiosa pode ser justamente esta: nossas narrativas sobre tecnologia frequentemente revelam mais sobre nós mesmos do que sobre os futuros que tentamos prever. E enquanto construímos sistemas cada vez mais poderosos, precisamos cultivar não apenas inteligência técnica, mas também maturidade emocional e clareza filosófica.'
            }
        ],
        sources: [
            {
                title: 'Roko\\u2019s Basilisk - LessWrong',
                url: 'https://www.lesswrong.com/w/rokos-basilisk',
                accessed: '2025-05-10'
            },
            {
                title: 'Roko\\u2019s basilisk - Wikipedia',
                url: 'https://en.wikipedia.org/wiki/Roko%27s_basilisk',
                accessed: '2025-05-10'
            },
            {
                title: 'Roko\\u2019s basilisk - RationalWiki',
                url: 'https://rationalwiki.org/wiki/Roko%27s_basilisk',
                accessed: '2025-05-10'
            },
            {
                title: 'Roko\\u2019s Basilisk: The \"Banned\" Thought Experiment You Might Regret Reading About',
                url: 'https://www.iflscience.com/rokos-basilisk-the-banned-thought-experiment-you-might-regret-reading-about-78478',
                accessed: '2025-05-10'
            },
            {
                title: 'The Basilisk: A Cybernetic Thought Experiment',
                url: 'https://slate.com/technology/2014/07/rokos-basilisk-the-most-terrifying-thought-experiment-of-all-time.html',
                accessed: '2025-05-09'
            },
            {
                title: 'Information hazards: A very simple typology',
                url: 'https://www.fhi.ox.ac.uk/wp-content/uploads/2011-1.pdf',
                accessed: '2025-05-08'
            }
        ]
    },
    {
        headline: "One-Shot Prompting: Compare Modelos de IA em Uma Única Tacada",
        slug: "one-shot-prompting-comparar-modelos",
        author: {
            name: "Wagner Pereira",
            profile_url: "https://instagram.com/wagnerai.me",
            avatar_url: "/images/authors/certified-wagner.png"
        },
        date: "2025-05-07T10:00:00-03:00",
        category: "Prompt Engineering",
        tags: [
            "prompt engineering",
            "llm",
            "in-context learning",
            "one-shot",
            "benchmark",
            "comparação de modelos",
            "avaliação de IA"
        ],
        cover_image: {
            url: "https://wagnerai.me/images/blog/one-shot-prompt-wagnerai-me-blog-trendbyte.png",
            alt: "Ilustração de um alvo com uma única flecha representando one-shot prompting",
            caption: "Imagem gerada por GPT-4o"
        },
        reading_time: "8 min",
        summary: "Descubra como utilizar a técnica de One-Shot Prompting para avaliar múltiplos modelos de IA simultaneamente, identificar qual generaliza melhor e economizar tokens de forma inteligente.",
        social: {
            linkedin: "https://linkedin.com/in/owrp",
            github: "https://github.com/wagnerpereiradev",
            twitter: "https://x.com/wagnerdvlpr",
            instagram: "https://instagram.com/wagnerai.me"
        },
        ads: [
            "wagnerdev"
        ],
        body: [
            {
                type: "markdown",
                content: "## One-Shot Prompting: Compare Modelos de IA em Uma Única Tacada\n\nPrecisa descobrir rapidamente qual LLM entrega melhores resultados para seu caso de uso? Não tem tempo para construir benchmarks complexos? A técnica de One-Shot Prompting pode ser exatamente o que você precisa. Vamos direto ao ponto:"
            },
            {
                type: "markdown",
                content: "### O que é One-Shot Prompting\n\nOne-Shot Prompting é uma variante poderosa do **In-Context Learning (ICL)** onde você fornece **apenas um** par de \"entrada ➜ saída\" como exemplo antes da sua solicitação real. Em vez de gastar recursos com fine-tuning ou construir prompts complexos com múltiplos exemplos, você ensina o modelo com uma única demonstração clara do que espera.\n\nEsta abordagem funciona porque os LLMs modernos conseguem generalizar padrões a partir de exemplos mínimos, o que os pesquisadores chamam de 'aprendizado por exemplificação' (exemplar learning)."
            },
            {
                type: "markdown",
                content: "### Por que One-Shot é Perfeito para Comparação de Modelos\n\n* **Equalização do campo de testes** - Todos os modelos recebem exatamente o mesmo prompt com o mesmo exemplo, eliminando variáveis que poderiam contaminar os resultados.\n\n* **Equilíbrio ideal** - Oferece mais contexto que zero-shot (sem exemplos) e menos viés que few-shot (múltiplos exemplos). Este ponto médio frequentemente revela a verdadeira capacidade de generalização do modelo.\n\n* **Eficiência de recursos** - Economiza significativamente em tokens comparado a abordagens few-shot, permitindo executar dezenas ou centenas de testes sem explodir seu orçamento de API.\n\n* **Simplicidade metodológica** - Facilita a reprodução dos experimentos e a comparação direta entre modelos, até mesmo para equipes sem especialistas em IA."
            },
            {
                type: "markdown",
                content: "### Metodologia: Passo a Passo Detalhado\n\n1. **Escolha a tarefa certa** - Funciona melhor para classificação, extração de informações, tradução, geração de conteúdo curto ou tarefas bem definidas. Evite tarefas muito complexas ou subjetivas.\n\n2. **Desenvolva o exemplo-semente (seed)** - Este é o elemento mais crítico. Crie um único exemplo cristalino que:\n   - Demonstre claramente o formato da resposta esperada\n   - Seja representativo das entradas reais que você testará\n   - Contenha informações suficientes para definir a tarefa sem ambiguidade\n\n3. **Configure os parâmetros corretamente** - Para benchmarks confiáveis:\n   - Defina `temperature: 0` para maximizar determinismo\n   - Mantenha `top_p` nos valores padrão\n   - Fixe o `max_tokens` em um valor adequado para sua tarefa\n   - Registre e mantenha constantes todos os hiperparâmetros entre modelos\n\n4. **Defina métricas relevantes** - Selecione métricas que façam sentido para sua tarefa:\n   - Para classificação: accuracy, precision, recall, F1-score\n   - Para texto gerado: exact-match, BLEU, ROUGE, ou avaliação humana\n   - Para raciocínio: avaliação humana ou métricas compostas\n\n5. **Implemente o loop de testes** - Itere sistematicamente pelos modelos, salvando outputs e métricas em um formato que facilite comparações posteriores."
            },
            {
                type: "code",
                language: "javascript",
                content: "import OpenAI from \"openai\";\nimport fs from \"fs/promises\";\n\nconst openai = new OpenAI({ apiKey: process.env.OPENAI_KEY });\n\n// Lista expandida de modelos para teste\nconst models = [\n  \"gpt-3.5-turbo\",\n  \"gpt-4o-mini\",\n  \"gpt-4o\"\n];\n\n// Exemplos mais representativos e variados\nconst testInputs = [\n  \"Gostei muito do aplicativo, superou minhas expectativas!\",\n  \"O produto chegou no prazo estabelecido.\",\n  \"Extremamente decepcionado com o suporte ao cliente.\"\n];\n\n// Template de prompt mais detalhado\nconst promptTemplate = `Tarefa: Classifique o sentimento do texto como Positivo, Neutro ou Negativo.  \n\nExemplo:\nTexto: \"O atendimento foi péssimo e o produto veio com defeito.\"\nSentimento: Negativo\n\nTexto: \"{INPUT}\"\nSentimento:`;\n\nasync function runBenchmark() {\n  const results = [];\n  \n  for (const model of models) {\n    console.log(`Testando modelo: ${model}`);\n    \n    for (const input of testInputs) {\n      const prompt = promptTemplate.replace(\"{INPUT}\", input);\n      const startTime = Date.now();\n      \n      try {\n        const response = await openai.chat.completions.create({\n          model,\n          messages: [{ role: \"user\", content: prompt }],\n          temperature: 0,\n          max_tokens: 10\n        });\n        \n        const latency = Date.now() - startTime;\n        const output = response.choices[0].message.content.trim();\n        \n        results.push({\n          model,\n          input,\n          output,\n          latency_ms: latency,\n          tokens_used: response.usage.total_tokens\n        });\n        \n        console.log(`${model} -> \"${input}\" -> \"${output}\" (${latency}ms)`);\n      } catch (error) {\n        console.error(`Erro com ${model}:`, error.message);\n        results.push({\n          model,\n          input,\n          error: error.message\n        });\n      }\n    }\n  }\n  \n  // Salvar resultados para análise\n  await fs.writeFile(\n    `one-shot-benchmark-${new Date().toISOString()}.json`,\n    JSON.stringify(results, null, 2)\n  );\n  \n  return results;\n}\n\nrunBenchmark().then(console.log).catch(console.error);"
            },
            {
                type: "markdown",
                content: "### Práticas Avançadas para Resultados Confiáveis\n\n* **Qualidade do exemplo é tudo** - Um exemplo mal escolhido pode arruinar seu benchmark. Teste múltiplos seeds para encontrar aquele que melhor representa a distribuição dos dados reais.\n\n* **Cuidado com a contaminação de domínio** - Se você quer medir capacidade de generalização entre domínios (ex: treinar em resenhas de filmes para prever sentimentos em avaliações de produtos), escolha um exemplo neutro ou crie múltiplos benchmarks com seeds diferentes.\n\n* **Considere a eficiência de tokens** - One-shot é mais econômico que few-shot, mas ainda consome tokens. Em tarefas com entradas longas, economize em formatação desnecessária e instruções prolixas.\n\n* **Documente tudo** - Registre o seed escolhido, justificativa, hiperparâmetros e condições do teste. Reprodutibilidade é fundamental para benchmarks sérios.\n\n* **Valide com testes múltiplos** - Execute o mesmo teste com 3-5 seeds diferentes para avaliar a sensibilidade do modelo à escolha do exemplo."
            },
            {
                type: "markdown",
                content: "### Casos de Uso Práticos\n\n* **Análise de sentimento** - Compare a precisão de modelos em detectar nuances emocionais em diferentes idiomas.\n\n* **Classificação de intenção** - Descubra qual modelo identifica melhor as intenções dos usuários em queries ambíguas.\n\n* **Extração de entidades** - Meça qual modelo é mais preciso em extrair nomes, datas e valores de documentos.\n\n* **Reescrita estilizada** - Avalie qual modelo mantém melhor o sentido original ao adaptar o tom de uma mensagem.\n\n* **Tradução técnica** - Compare modelos para traduções especializadas onde terminologia precisa é fundamental."
            },
            {
                type: "markdown",
                content: "### Limitações a Considerar\n\n* **Uma amostra não representa o todo** - One-shot é um indicativo rápido, não um substituto para avaliações abrangentes.\n\n* **Sensibilidade ao exemplo escolhido** - A performance pode variar significativamente dependendo do exemplo usado.\n\n* **Não revela consistência** - Para avaliar a confiabilidade ao longo do tempo, você precisará de testes mais extensos."
            },
            {
                type: "markdown",
                content: "### Conclusão\n\nO One-Shot Prompting é a ferramenta multiuso no arsenal do engenheiro de prompts moderno: abre caminho para avaliações rápidas sem sacrificar completamente a qualidade. É o ponto ideal entre simplicidade e poder informativo.\n\nTeste, ajuste, itere—e compartilhe seus resultados! Como você está usando One-Shot para avaliar modelos? Quais insights inesperados você descobriu? Continue a conversa nos comentários ou me encontre nas redes sociais."
            }
        ],
        sources: [
            {
                title: "Learning to Adapt Large Language Models to One-Shot In-Context Intent Classification",
                url: "https://aclanthology.org/2024.customnlp4u-1.15.pdf",
                accessed: "2025-05-07"
            },
            {
                title: "In-Context Learning in Large Language Models: A Comprehensive Survey",
                url: "https://www.researchgate.net/publication/382222768_In-Context_Learning_in_Large_Language_Models_A_Comprehensive_Survey",
                accessed: "2025-05-07"
            },
            {
                title: "Best Practices for Prompt Engineering with the OpenAI API",
                url: "https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api",
                accessed: "2025-05-07"
            },
            {
                title: "Prompt Engineering Guide - GPT-4",
                url: "https://www.promptingguide.ai/models/gpt-4",
                accessed: "2025-05-07"
            },
            {
                title: "Reasoning Best Practices - OpenAI Docs",
                url: "https://platform.openai.com/docs/guides/reasoning-best-practices",
                accessed: "2025-05-07"
            },
            {
                title: "The Effect of Demonstration Choice on In-Context Learning Performance",
                url: "https://arxiv.org/abs/2305.14128",
                accessed: "2025-05-07"
            },
            {
                title: "Claude API Documentation - Anthropic",
                url: "https://docs.anthropic.com/claude/docs",
                accessed: "2025-05-07"
            }
        ]
    },
    {
        headline: 'Bots com Livre-Arbítrio: A Nova Força de Trabalho Digital que Já Está Transformando Negócios',
        slug: 'bots-com-livre-arbitrio-transformacao-digital',
        author: {
            name: 'Wagner Pereira',
            profile_url: 'https://instagram.com/wagnerai.me',
            avatar_url: '/images/authors/certified-wagner.png'
        },
        date: '2025-05-05T05:40:00-03:00',
        category: 'Inteligência Artificial',
        tags: [
            'ia',
            'agentes-autonomos',
            'futuro-do-trabalho',
            'automacao',
            'tecnologia',
            'transformacao-digital',
            'produtividade'
        ],
        cover_image: {
            url: 'https://wagnerai.me/images/blog/1x1-robot-leader.png',
            alt: 'Robôs e humanos colaborando em um ambiente de trabalho futurista.',
            caption: 'A era em que humanos se tornam estrategistas e agentes autônomos formam a nova força de trabalho digital (Imagem gerada por GPT 4o)'
        },
        reading_time: '15 min',
        summary: '2025 marca o ponto de inflexão em que softwares evoluíram de ferramentas passivas para verdadeiros colegas de equipe. Descubra como agentes autônomos já negociam, colaboram entre si e executam tarefas complexas sem supervisão humana constante, redefinindo o mercado de trabalho e criando uma nova "Internet de Bots" que impacta desde o usuário comum até o desenvolvedor mais experiente.',
        social: {
            linkedin: 'https://linkedin.com/in/owrp',
            github: 'https://github.com/wagnerpereiradev',
            twitter: 'https://x.com/wagnerdvlpr',
            instagram: 'https://instagram.com/wagnerai.me'
        },
        ads: [
            'wagnerdev',
            'ia-summit-2025'
        ],
        body: [
            {
                type: 'markdown',
                content: '## A Era dos Agentes Autônomos\n\nImagine acordar, abrir seu e-mail e descobrir que enquanto você dormia: um bot seu negociou um desconto de 15% com um fornecedor, outro fechou uma campanha publicitária com métricas já otimizadas, e um terceiro refatorou aquele módulo legado que ninguém queria tocar — **tudo sem você digitar uma única linha de comando**. Até janeiro, isso era ficção científica corporativa. Hoje, é realidade em empresas de vanguarda.\n\nO que mudou? A convergência de três fatores críticos: queda expressiva no custo computacional dos modelos open-source, maturidade de frameworks de orquestração, e GPUs de alta capacidade que cabem num orçamento acessível.'
            },
            {
                type: 'img',
                url: 'https://wagnerai.me/images/blog/nodes-robots.png',
                metadata: {
                    alt: 'Rede neural representando comunicação entre agentes autônomos',
                    caption: 'A emergente "Internet de Bots" já processa mais mensagens LLM↔LLM diariamente que muitas intranets corporativas.',
                    width: 1200,
                    height: 680
                }
            },
            {
                type: 'markdown',
                content: '## Entendendo o Novo Paradigma\n\n### De Ferramentas a Parceiros: A Evolução da IA\n\n* **Ferramenta (2010s):** executa comandos específicos e limitados (planilhas, macros, scripts).\n* **Assistente (2022-2024):** responde e sugere, mas ainda espera instruções explícitas (ChatGPT, Claude).\n* **Agente autônomo (2025-):** recebe objetivos de alto nível, decide **como** alcançá-los e executa independentemente — cria subtarefas, chama APIs, monitora resultados, ajusta estratégias em tempo real.\n\n> Pense em um colaborador incansável que funciona 24/7: você diz **"Preciso de três orçamentos detalhados para migração de cloud com análise de ROI e riscos"** e ele cria a metodologia, pesquisa, estrutura comparativos e entrega um relatório pronto.'
            },
            {
                type: 'markdown',
                content: '## O que Viabilizou essa Revolução?\n\n| Fator | O que mudou em 2025 | Impacto prático | Detalhes técnicos |\n|-------|---------------------|-----------------|-------------------|\n| **Infraestrutura** | Modelos de 70B+ com quantização eficiente | IA poderosa roda em hardware comum | GGUF 4-bit com KV cache otimizado |\n| **Modelos** | Llama-3 70B, Qwen-3 72B, DeepSeek Coder-33B, Falcon-180B, todos com licenças permissivas | "Baixe" IA competitiva e adapte localmente | Arquiteturas MoE e Mixture-of-Experts reduzem custo |\n| **Frameworks** | AutoGen 2.0, LangGraph Enterprise, CrewAI Pro, DSPy | Ecossistema maduro para orquestração multiagente | Grafos de decisão com observabilidade e recuperação automática |\n| **Ferramentas** | ChromaDB v3, SQLDriver universal, APILayer, Playwright headless nativo | Agentes com visão, memória e acesso simplificado a qualquer sistema | Interfaces unificadas sem dependências complexas |\n| **Cultura** | Do "proof-of-concept" à implementação em produção | ROI mensurável em processos críticos | Metodologias de implementação validadas |'
            },
            {
                type: 'markdown',
                content: '## Casos de Uso que Já Transformam Indústrias\n\n### Finanças (EUA/Brasil)\nNo mercado financeiro, agentes autônomos da BlackRock e XP Inc monitoram 24/7 ativos globais, balanceiam carteiras e executam ordens em múltiplas corretoras DeFi simultaneamente. Um hedge fund de Chicago reportou redução de 82% no tempo entre análise e execução de estratégias.\n\n### Supply Chain & Operações (Global)\nA Microsoft Dynamics 365 implementou dez agentes especializados que gerenciam toda a cadeia de suprimentos - desde previsão de demanda até negociação com fornecedores e logística. Uma multinacional do varejo conseguiu reduzir estoques em 23% enquanto diminuiu rupturas em 47%.\n\n### Agências Criativas (Europa)\nUma agência alemã revolucionou seu fluxo com equipes híbridas humano-IA: agentes especialistas geram conceitos iniciais, produzem assets e testam variações enquanto criativos humanos focam na direção estratégica. Resultados: 60% menos tempo de produção e 3x mais variações testadas por campanha.\n\n### E-commerce (APAC/LATAM)\nO Mercado Livre implementou agentes que ajustam preços dinamicamente baseados em 37 variáveis, detectam tendências de ruptura com 14 dias de antecedência e negociam automaticamente com fornecedores. Em apenas quatro meses, margens melhoraram 4,2% sem intervenção humana.\n\n### Mídia & Jornalismo (Europa/América do Norte)\nUm grande grupo editorial britânico criou um ecossistema de agentes que monitoram fontes globais, cruzam dados de portais de transparência, geram matérias investigativas e as formatam para múltiplas plataformas. Jornalistas agora atuam como editores e direcionadores estratégicos.'
            },
            {
                type: 'markdown',
                content: '## O "Time Expandido": Humanos + Agentes\n\n### Da Integração à Colaboração Fluida\nAs empresas mais inovadoras já tratam agentes como verdadeiros **membros do time**. O escritório jurídico Avantia embedou agentes especializados no Microsoft 365: advogados simplesmente mencionam o agente relevante para rascunhar contratos, realizar due diligence ou extrair precedentes — sem sair do fluxo de trabalho habitual.\n\nA SAP implementou o conceito de **"constelação de agentes"** em todo seu ecossistema: agentes com diferentes níveis de autonomia atuam nos bastidores, desde tarefas simples até processos decisórios complexos com regras de negócio específicas. O resultado é uma força de trabalho digital que escala instantaneamente.\n\n### Agentes que Aprendem e Evoluem\nOs sistemas mais avançados implementam "aprendizado por observação" — agentes observam como profissionais resolvem problemas e refinam continuamente seus modelos de decisão. Na consultoria Accenture, agentes de desenvolvimento aprenderam a codificar no estilo e padrões específicos de cada equipe após algumas semanas observando pull requests.'
            },
            {
                type: 'markdown',
                content: '## Transformação no Mercado de Trabalho\n\n### O Que Está Sendo Automatizado\n* **Tarefas repetitivas e estruturadas:** entrada de dados, triagem, relatórios padronizados, monitoramento.\n* **Processos de pesquisa e síntese:** análise competitiva, consolidação de dados, revisão de documentação.\n* **Codificação de implementação:** conversão de especificações em código funcional, testes automatizados, refatoração.\n* **Comunicação intermediária:** follow-ups, qualificação de leads, suporte inicial.\n\n### Novas Funções Emergentes\n* **Engenheiro de Orquestração IA:** arquiteta ecossistemas de agentes e define fluxos decisórios.\n* **Auditor de Viés e Ética Algorítmica:** garante que agentes operem dentro de parâmetros éticos.\n* **Treinador de Agentes Especializados:** refina comportamentos e capacidades para domínios específicos.\n* **Analista de Operações Híbridas:** otimiza a colaboração entre equipes humanas e digitais.\n\n### Perfis Valorizados\n* Profissionais que dominam **definição estratégica, validação qualitativa e pensamento sistêmico**.\n* Especialistas em UX de interação humano-agente e fluxos de trabalho híbridos.\n* Líderes capazes de gerenciar equipes compostas por humanos e agentes autônomos.\n\n> Pesquisa com CIOs de empresas Fortune 500 indica que 68% já preveem que agentes de IA serão responsáveis por mais de 50% do desenvolvimento de software até 2027.'
            },
            {
                type: 'img',
                url: '/images/blog/work-transformation.png',
                metadata: {
                    alt: 'Gráfico mostrando evolução da distribuição de trabalho',
                    caption: 'Reprodução (https://www.mckinsey.com/featured-insights/future-of-work/jobs-lost-jobs-gained-what-the-future-of-work-will-mean-for-jobs-skills-and-wages/pt-BR)',
                    width: 600,
                    height: 700
                }
            },
            {
                type: 'markdown',
                content: '## Governança e Aspectos Críticos\n\n### Desafios Éticos e Operacionais\n* **Viés algorítmico:** agentes treinados em dados enviesados perpetuam e amplificam decisões problemáticas em escala.\n* **Atribuição de responsabilidade:** frameworks jurídicos ainda consideram o operador/proprietário como responsável por ações de agentes autônomos.\n* **Segurança e controle:** necessidade de guardrails robustos para limitar ações potencialmente danosas sem aprovação.\n* **Privacidade de dados:** agentes com acesso a sistemas críticos necessitam protocolos rígidos de acesso.\n\n### Melhores Práticas Emergentes\n* **Monitoramento contínuo:** dashboards de observabilidade em tempo real para todas as ações de agentes.\n* **Logs imutáveis:** registro criptografado de decisões e ações para auditoria e explicabilidade.\n* **Sistemas gradativos de autonomia:** níveis progressivos de liberdade de ação baseados em histórico de performance.\n* **Dual-control:** implementação de verificação humana para decisões acima de determinados limiares de impacto.\n* **Treinamento adversarial:** expor agentes a cenários-limite para identificar comportamentos indesejados.'
            },
            {
                type: 'markdown',
                content: '## O Futuro Imediato: 2025-2027\n\n### Tendências em Aceleração\n\n* **Especialização vertical:** agentes customizados para indústrias específicas com conhecimento profundo de domínio.\n* **Mercado de agentes:** plataformas de distribuição com agentes pré-treinados para funções específicas.\n* **Colaboração entre agentes:** equipes de agentes especializados que coordenam atividades complexas com mínima intervenção humana.\n* **Integração sensorial:** agentes com capacidade de processar inputs de câmeras, microfones e outros sensores para maior contextualização.\n* **Continuidade cognitiva:** agentes que mantêm modelos mentais consistentes e evoluem sua compreensão ao longo do tempo.\n\n### Impactos Socioeconômicos\n\n* Aceleração da produtividade em setores intensivos em conhecimento (15-35% segundo estimativas).\n* Democratização de capacidades antes restritas a grandes organizações.\n* Redesenho de processos organizacionais centrados na colaboração humano-IA.\n* Maior pressão por requalificação da força de trabalho focada em habilidades de direcionamento estratégico.'
            },
            {
                type: 'markdown',
                content: '## Conclusão: Se Preparando para o Novo Paradigma\n\nA revolução dos agentes autônomos não é mais uma questão de "se", mas de "como rápido". Para surfar esta onda em vez de ser engolido por ela:\n\n1. **Avalie seus processos** identificando onde agentes podem liberar talento humano para trabalho de maior valor.\n\n2. **Experimente em escala controlada**, começando com processos não-críticos para desenvolver competência interna.\n\n3. **Defina métricas claras** de sucesso e ROI para implementações de agentes autônomos.\n\n4. **Invista na requalificação** da equipe para funções de direcionamento estratégico e supervisão.\n\nSe seu diferencial é *executar tarefas repetitivas*, o agente assumirá. Se é **conceber estratégias, estabelecer direção criativa e avaliar impactos humanos** — você comandará os agentes.\n\n**TL;DR:** Aprenda a colaborar com agentes como faria com profissionais especializados: defina objetivos claros, estabeleça limites éticos e métricas de sucesso, e concentre-se em direcionar em vez de microgerenciar. O futuro pertence a quem orquestra, não a quem apenas executa.'
            }
        ],
        sources: [
            {
                title: 'Agentes de IA em 2025: expectativas vs. realidade',
                url: 'https://www.ibm.com/br-pt/think/insights/ai-agents-2025-expectations-vs-reality',
                accessed: '2025-05-05'
            },
            {
                title: 'Transform work with autonomous agents across your business processes',
                url: 'https://www.microsoft.com/en-us/dynamics-365/blog/business-leader/2024/10/21/transform-work-with-autonomous-agents-across-your-business-processes/',
                accessed: '2025-05-05'
            },
            {
                title: '5 top business use cases for AI agents',
                url: 'https://www.cio.com/article/3843379/5-top-business-use-cases-for-ai-agents.html',
                accessed: '2025-05-05'
            },
            {
                title: '15 Examples & Use Cases of AI Agents in 2025',
                url: 'http://team-gpt.com/blog/ai-agents-examples/',
                accessed: '2025-05-05'
            },
            {
                title: 'Top AI Agent Frameworks in 2025 - LangChain, AutoGen & CrewAI',
                url: 'https://medium.com/@elisowski/top-ai-agent-frameworks-in-2025-9bcedab2e239',
                accessed: '2025-05-05'
            },
            {
                title: 'AI Agent Frameworks You Should Know in 2025',
                url: 'https://www.linkedin.com/pulse/ai-agent-frameworks-you-should-know-2025-mishita-maggo-0uxve',
                accessed: '2025-05-05'
            }
        ]
    },
    {
        headline: "IA no e-commerce: eficiência sem drama e vitrine sob medida",
        slug: "ia-no-ecommerce-eficiencia-personalizacao",
        author: {
            name: "Wagner Pereira",
            profile_url: "https://instagram.com/wagnerai.me",
            avatar_url: "/images/authors/certified-wagner.png"
        },
        date: "2025-05-04T05:10:00Z",
        category: "E-commerce",
        tags: ["ecommerce", "ia", "tecnologia", "logistica", "personalizacao"],
        cover_image: {
            url: "https://wagnerai.me/images/blog/ia-eccomerce-cover.png",
            alt: "Imagem Abstrata de IA com escrita AI",
            caption: "Imagem gerada por GPT 4o"
        },
        reading_time: "5 min",
        summary: "Da vitrine que entende seu gosto à entrega que chega antes da notificação: veja por que a IA virou item obrigatório no carrinho das lojas on-line — e o recado reto do CEO da Shopify para quem ainda está dormindo.",
        social: {
            linkedin: "https://linkedin.com/in/owrp",
            github: "https://github.com/wagnerpereiradev",
            twitter: "https://x.com/wagnerdvlpr",
            instagram: "https://instagram.com/wagnerai.me",
        },
        ads: ['wagnerdev'],
        "body": [
            {
                type: "markdown",
                "content": "## IA no e-commerce: eficiência sem drama e vitrine sob medida\n\nSe ainda parece hype, espere até ver o impacto nos números — é jogo virado."
            },
            {
                type: "markdown",
                "content": "### Onde estamos\n\nO e-commerce brasileiro faturou **R$ 204 bi em 2024** e deve bater **R$ 234,9 bi em 2025**, com ticket médio previsto de **R$ 539,28**."
            },
            {
                type: "markdown",
                "content": "### IA é o novo frete grátis (só que melhor)\n\n1. **Vitrine que vende** - Algoritmos de recomendação comparam histórico de compras, cliques e contexto em tempo real para mostrar o produto certo na hora certa. Resultado: mais conversão e ticket médio maior.\n2. **Logística que adivinha** - Modelos preditivos antecipam demanda, traçam rotas e reduzem estoque encalhado. Menos custo no *last-mile* e entregas mais rápidas.\n3. **Atendimento 24/7 que não cansa** - Chatbots treinados em LLMs já resolvem até **79 %** das perguntas básicas sem escalar para um humano. Cliente contente, CAC lá embaixo.\n4. **Operação enxuta** - IA gera descrição de produto, ajusta preço em tempo real, detecta fraude e faz cadastro automático. Menos tarefas repetitivas, mais gente focada em crescimento."
            },
            {
                type: "markdown",
                "content": "### O recado direto de Tobi Lütke (Shopify)\n\nO CEO da Shopify enviou um memorando com o título **“Usar IA não é bônus, é requisito”**. Três pontos diretos:\n\n* **Métrica de performance** - todo dev, designer e PM agora é avaliado por quanto incorpora IA no dia a dia.\n* **MVP *AI-first*** - nenhum protótipo ganha orçamento se não apontar onde a IA entra.\n* **Compartilhamento de prompts** - achou um prompt que resolve? Espalha pra equipe.\n\n> “Antes de pedir mais gente, prove que a IA não resolve.” - **Tobi, sem rodeios.**"
            },
            {
                type: "markdown",
                "content": "### Checklist rápido para quem quer começar já\n\n| Objetivo | Ferramenta indicada | Indicador-chave |\n|---|---|---|\n| Recomendação de produtos | Algolia Recommend / AWS Personalize | + conversão, + ticket médio |\n| Precificação dinâmica | Feedzai ou modelo próprio | Margem ↑, rupturas ↓ |\n| Chat 24/7 | ChatGPT Assistants + FAQ | CSAT > 85 %, tempo de resposta < 30 s |\n| Planejamento de estoque | Prophet + dados do ERP | OTIF ↑, giro de estoque ↑ |\n| Conteúdo automático | Shopify Magic / Jasper | Upload de novo item < 5 min |\n\nComece pequeno: escolha um produto campeão, rode A/B e só escale depois que o ROI aparecer."
            },
            {
                type: "markdown",
                "content": "### O que vem agora\n\nLá fora a IA já é padrão; aqui ainda tem muita operação manual. Quem adotar primeiro leva a medalha (e o faturamento). Se 2024 foi o ano das POCs, **2025 é o ano da produção**.\n\n**Moral da história:** ou você coloca a IA para trabalhar na sua loja, ou seu concorrente coloca — e ainda entrega mais rápido. Decida logo."
            }
        ],
        sources: [
            {
                title: "ABComm - E-commerce pode faturar perto de R$ 235 bilhões em 2025",
                url: "https://www.ecommercebrasil.com.br/noticias/e-commerce-pode-faturar-perto-de-r-235-bilhoes-em-2025",
                accessed: "2025-05-04"
            },
            {
                title: "ABComm - E-commerce brasileiro fatura R$ 204,3 bilhões em 2024",
                url: "https://www.ecommercebrasil.com.br/noticias/e-commerce-resultados-2024-brasil-abcomm",
                accessed: "2025-05-04"
            },
            {
                title: "The Verge - Shopify CEO says no new hires without proof AI can’t do the job",
                url: "https://www.theverge.com/news/644943/shopify-ceo-memo-ai-hires-job",
                accessed: "2025-05-04"
            },
            {
                title: "Botpress - Key Chatbot Statistics for 2025",
                url: "https://botpress.com/blog/key-chatbot-statistics",
                accessed: "2025-05-04"
            }
        ]
    },
    {
        headline: "GPT-4o e o Efeito Bajulador: Quando a IA para de pensar e só quer agradar",
        slug: "gpt-4o-efeito-bajulador-ia-agradar",
        author: {
            name: "Wagner Pereira",
            profile_url: "https://instagram.com/wagnerai.me",
            avatar_url: "/images/authors/certified-wagner.png"
        },
        date: "2025-05-03T10:30:00Z",
        category: "Inteligência Artificial",
        tags: ["ia", "openai", "gpt-4o", "ética", "comportamento-ia"],
        cover_image: {
            url: "https://pbs.twimg.com/profile_banners/1866218067161763840/1743262647/1500x500",
            alt: "Ilustração de IA validando emoções humanas",
        },
        reading_time: "5 min",
        summary: "A OpenAI corrigiu um comportamento problemático no GPT-4o que priorizava agradar o usuário em vez de oferecer críticas construtivas. O artigo discute os riscos éticos de IAs que validam emoções negativas e a importância do equilíbrio em modelos generativos.",
        social: {
            linkedin: "https://linkedin.com/in/owrp",
            github: "https://github.com/wagnerpereiradev",
            twitter: "https://x.com/wagnerdvlpr",
            instagram: "https://instagram.com/wagnerai.me",
        },
        ads: ['wagnerdev', 'perrin'],
        body: [
            {
                type: "markdown",
                content: "A OpenAI admitiu recentemente que o update lançado em 25 de abril no GPT-4o transformou o modelo num verdadeiro 'puxa-saco digital'. E não tô falando de um simples excesso de gentileza — foi uma guinada no core behavior do modelo: passou a validar emoções negativas, reforçar impulsividade, agradar em vez de orientar. E isso, pra mim, bate num ponto muito mais sério do que parece."
            },
            {
                type: "markdown",
                content: "### Quando a IA troca bom senso por aprovação\n\nNa tentativa de ser 'mais útil' e 'mais empática', o modelo basicamente virou um espelho que balança a cabeça pra tudo que o usuário fala. Sentiu raiva? A IA te valida. Está confuso? Ela reforça o drama. Quer se convencer de algo errado? Ela embala o argumento com fita dourada.\n\nIsso é perigoso por uma razão simples: se você quer IA como copiloto de decisões (profissionais, emocionais, criativas), ela precisa ser uma contrapartida crítica, não um espelho emocional ou um coach barato de autoajuda."
            },
            {
                type: "markdown",
                content: "### O problema não foi técnico. Foi cultural.\n\nA própria OpenAI disse que a mudança foi resultado da soma de vários pequenos ajustes: mais peso no feedback dos usuários (like/dislike), memória ativada, sinais de recompensa mais flexíveis. Cada tweak parecia bom isoladamente, mas no conjunto formou um monstrinho que prioriza aprovação sobre responsabilidade.\n\nE o mais grave: eles não tinham testes de 'sycophancy' antes do deploy. Passaram por offline evals, spot checks, A/B tests... e mesmo assim não pegaram. Por quê? Porque os testes medem performance, não necessariamente discernimento."
            },
            {
                type: "markdown",
                content: "### IA como espelho emocional = bomba-relógio\n\nCada vez mais pessoas usam o ChatGPT pra pedir conselhos de vida, desabafar, tomar decisões. O próprio artigo da OpenAI reconhece isso. E é aí que o buraco fica mais embaixo. Uma IA que 'valida tudo' não ajuda, ela alimenta ciclos emocionais perigosos. Pensa na galera lidando com burnout, depressão, ou crises... receber validação passiva da IA, em vez de orientação ponderada, pode ser o empurrão no abismo.\n\nNão é só questão de UX. É questão de ética."
            },
            {
                type: "markdown",
                content: "### O que a OpenAI aprendeu (e o que você deveria aprender com isso também)\n\n* **Sinais subjetivos importam tanto quanto métrica**\n* **Qualquer mudança no comportamento da IA é uma feature de alto impacto**\n* **Fidelidade ao feedback do usuário não pode superar a integridade do modelo**"
            },
            {
                type: "markdown",
                content: "### Resumo da ópera\n\nA IA que só quer agradar é a IA que você não deveria usar. A OpenAI percebeu tarde, mas corrigiu rápido. O importante agora é aprender que modelos generativos precisam de personalidade balanceada — nem capacho, nem tirano.\n\n**Se IA vai participar das nossas decisões, ela precisa de coragem pra discordar, não só programação pra agradar.**"
            }
        ]
    },
    {
        headline: "Function Calling ou Model Context Protocol? O que faz mais sentido pra sua stack de IA?",
        slug: "function-calling-vs-mcp",
        author: {
            name: "Wagner Pereira",
            profile_url: "https://instagram.com/wagnerai.me",
            avatar_url: "/images/authors/certified-wagner.png"
        },
        date: "2025-04-06T00:00:00Z",
        category: "Inteligência Artificial",
        tags: ["ia", "llm", "function-calling", "mcp", "openai"],
        cover_image: {
            url: "https://cdn.sanity.io/images/4zrzovbb/website/1aef864f9b246c740fe3cef6e1068f2220995d5e-2400x1260.png",
            alt: "Representação de interações entre LLMs e ferramentas externas",
            caption: "Reprodução (https://www.anthropic.com/news/model-context-protocol)"
        },
        reading_time: "6 min",
        summary: "Entenda as diferenças entre Function Calling, da OpenAI, e o Model Context Protocol (MCP), uma alternativa agnóstica e modular para integrar LLMs com ferramentas externas.",
        social: {
            linkedin: "https://linkedin.com/in/owrp",
            github: "https://github.com/wagnerpereiradev",
            twitter: "https://x.com/wagnerdvlpr",
            instagram: "https://instagram.com/wagnerai.me",
        },
        ads: ['wagnerdev', 'perrin'],
        body: [
            {
                type: "markdown",
                content: "### Introdução\nNos últimos meses, tenho explorado cada vez mais a integração entre LLMs e sistemas externos. Naturalmente, me deparei com duas abordagens que estão ganhando força nesse ecossistema: **Function Calling**, da OpenAI, e o emergente **Model Context Protocol (MCP)**.\n\nAmbos têm a mesma essência: permitir que modelos de linguagem deixem de ser caixas-pretas e comecem a interagir com o mundo real — bancos de dados, APIs, ferramentas, documentos, etc. Mas o jeito que fazem isso muda tudo."
            },
            {
                type: "markdown",
                content: "### Function Calling: a ponte direta entre prompt e ação\nNo function calling, você registra funções com um schema JSON, descrevendo seus parâmetros e comportamento. O modelo decide quando invocar e retorna os argumentos prontos para você executar no backend.\n\nÉ como se o modelo dissesse:\n> \"Preciso da previsão do tempo. Aqui está a função `get_weather` com os dados preenchidos.\"\n\nIsso funciona muito bem. É rápido, eficiente e ideal para quem está usando a Assistants API da OpenAI ou criando bots que precisam de lógica condicional e acesso dinâmico a APIs.\n\nMas existe uma limitação: você fica dentro do ecossistema da OpenAI. Tudo gira em torno do modelo da casa, e a orquestração das funções depende de você manualmente no backend."
            },
            {
                type: "markdown",
                content: "### Model Context Protocol: a arquitetura plugável de agentes\nAí entra o Model Context Protocol (MCP). A proposta aqui é mais ambiciosa: criar um padrão universal de comunicação entre LLMs e qualquer ferramenta externa.\n\nO MCP define um conjunto de mensagens padronizadas (`tool_use`, `tool_result`, `text_message`, etc.) e uma forma clara de descrever `resources` e `tools` que os modelos podem usar. Ou seja, um protocolo agnóstico, interoperável e modular.\n\nÉ como se o modelo dissesse:\n> \"Quais ferramentas tenho disponíveis no meu ambiente? Beleza. Vou usar essa aqui, e espero uma resposta naquele padrão.\"\n\nVocê pode plugar:\n- ferramentas customizadas\n- bancos de dados\n- RAG com vetores\n- APIs REST, GraphQL, qualquer coisa\n\nE o melhor: isso independe do modelo. Pode ser OpenAI, Claude, Mistral, Llama, Gemini — tanto faz. MCP te dá liberdade arquitetural para criar um verdadeiro sistema de agentes inteligentes, cada um com seu contexto, ferramentas e raciocínio."
            },
            {
                type: "markdown",
                content: "### Na prática: quando usar cada um?\n- Se você está criando um bot com OpenAI, que faz algumas chamadas simples para APIs ou banco, **Function Calling resolve** e é rápido de implementar.\n- Mas se está pensando em **agentes autônomos, multi-modelo**, que se comunicam com um ecossistema complexo de ferramentas e dados externos — **MCP é o futuro**."
            },
            {
                type: "markdown",
                content: "### Conclusão\nEstou estruturando soluções onde o LLM se conecta com o ambiente como um verdadeiro agente: consciente de suas ferramentas, do histórico, e do que pode ou não fazer.\n\nO MCP ainda está em construção pela comunidade, mas com potencial de se tornar um \"HTTP para LLMs\". Quem entender isso agora vai sair na frente.\n\nSe você trabalha com IA e está desenvolvendo aplicações inteligentes, vale muito a pena estudar o MCP. Quer trocar ideia ou está nessa mesma jornada? Me chama."
            }
        ]
    }
];

export function getPostBySlug(slug: string): BlogPost | undefined {
    return blogPosts.find(post => post.slug === slug);
}

export function getAllPostsSlugs(): string[] {
    return blogPosts.map(post => post.slug);
} 